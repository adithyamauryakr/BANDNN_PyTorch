{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adithyamauryakr/BANDNN_pytorch/blob/main/BANDNN_mirror.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit\n",
        "!git clone https://github.com/adithyamauryakr/BANDNN_pytorch.git\n",
        "!git clone https://github.com/isayev/ANI1_dataset.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0P5n8lBMJ1r",
        "outputId": "30f779b7-59f2-4a3f-835f-bd91dfb442c1"
      },
      "id": "Y0P5n8lBMJ1r",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2024.9.6-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit) (11.1.0)\n",
            "Downloading rdkit-2024.9.6-cp311-cp311-manylinux_2_28_x86_64.whl (34.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.3/34.3 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit\n",
            "Successfully installed rdkit-2024.9.6\n",
            "Cloning into 'BANDNN_pytorch'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 18 (delta 6), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (18/18), 27.24 KiB | 13.62 MiB/s, done.\n",
            "Resolving deltas: 100% (6/6), done.\n",
            "Cloning into 'ANI1_dataset'...\n",
            "remote: Enumerating objects: 81, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 81 (delta 6), reused 13 (delta 4), pack-reused 63 (from 1)\u001b[K\n",
            "Receiving objects: 100% (81/81), 2.69 MiB | 12.52 MiB/s, done.\n",
            "Resolving deltas: 100% (36/36), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export PYTHONPATH=\"${PYTHONPATH}:/content/ANI1_dataset/readers/lib to PYTHONPATH\""
      ],
      "metadata": {
        "id": "jzfxLFSFMfmZ"
      },
      "id": "jzfxLFSFMfmZ",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "437cff80",
      "metadata": {
        "id": "437cff80"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import lib.pyanitools as pya\n",
        "import os\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyPKElDqMigv",
        "outputId": "f1b917f8-6419-4090-af62-41760cf9cc6f"
      },
      "id": "yyPKElDqMigv",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "955caed5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "955caed5",
        "outputId": "08f42c93-deb5-4416-b7d8-898f95de30fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100000\n"
          ]
        }
      ],
      "source": [
        "import h5py\n",
        "\n",
        "features_list = []\n",
        "with h5py.File('/content/drive/MyDrive/bandnn_datasets/molecules.h5', 'r') as h5f:\n",
        "    for mol_key in h5f.keys():\n",
        "        group = h5f[mol_key]\n",
        "        mol_data = {key: group[key][()] for key in group}\n",
        "        # Decode bytes to strings if needed\n",
        "        for k, v in mol_data.items():\n",
        "            if isinstance(v, bytes):\n",
        "                mol_data[k] = v.decode('utf-8')\n",
        "        features_list.append(mol_data)\n",
        "\n",
        "print(len(features_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ba9ca7a6",
      "metadata": {
        "id": "ba9ca7a6"
      },
      "outputs": [],
      "source": [
        "y = pd.read_csv('/content/drive/MyDrive/bandnn_datasets/energy_list.csv').values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "92cab595",
      "metadata": {
        "id": "92cab595"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    features_list, y, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self, features, targets):\n",
        "    self.features = features\n",
        "    self.targets = torch.tensor(targets, dtype=torch.float32)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.targets)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.features[index], self.targets[index]"
      ],
      "metadata": {
        "id": "wXx8l8BjilfC"
      },
      "id": "wXx8l8BjilfC",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_fn(batch):\n",
        "    feature_batch, target_batch = zip(*batch)  # Unpack into tuples of features and targets\n",
        "    # Convert list of dicts to dict of lists/tensors\n",
        "    batch_dict = {key: torch.tensor([d[key] for d in feature_batch], dtype=torch.float32)\n",
        "                  for key in feature_batch[0]}\n",
        "    batch_targets = torch.tensor(target_batch, dtype=torch.float32)  # or torch.long if it's classification\n",
        "    return batch_dict, batch_targets"
      ],
      "metadata": {
        "id": "q1xgh7PllBCO"
      },
      "id": "q1xgh7PllBCO",
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_Fn(batch):\n",
        "    feature_batch, target_batch = zip(*batch)\n",
        "    return list(feature_batch), torch.tensor(target_batch, dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "EWbDL6aGmZnX"
      },
      "id": "EWbDL6aGmZnX",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dataset = CustomDataset(X_train, y_train)\n",
        "test_dataset = CustomDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32,collate_fn=collate_Fn, shuffle=True, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, collate_fn=collate_Fn, shuffle=False, pin_memory=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "Z7Mwawsci9Ft"
      },
      "id": "Z7Mwawsci9Ft",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_loader:\n",
        "  # this is in training loop\n",
        "  for feature_dict, target in zip(*batch):\n",
        "    print(len(feature_dict))\n",
        "    b_feat = [bond for bond in feature_dict['bonds']]\n",
        "    a_feat = [angle for angle in feature_dict['angles']]\n",
        "    n_feat = [nonbond for nonbond in feature_dict['nonbonds']]\n",
        "    d_feat = [dihedral for dihedral in feature_dict['dihedrals']]\n",
        "    b_input = [b for b in b_feat]\n",
        "    # in model\n",
        "    for b in b_input:\n",
        "      print(len(b))\n",
        "    break\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvZyHCSfnqtv",
        "outputId": "6ac049cd-9bcd-439d-c407-bd2af514f9b9"
      },
      "id": "HvZyHCSfnqtv",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "tensor(-379.8292)\n",
            "17\n",
            "17\n",
            "17\n",
            "17\n",
            "17\n",
            "17\n",
            "17\n",
            "17\n",
            "17\n",
            "17\n",
            "17\n",
            "17\n",
            "17\n",
            "17\n",
            "17\n",
            "17\n",
            "17\n",
            "17\n",
            "17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_loader:\n",
        "  for feature, target in zip(*batch):\n",
        "    a = [bond for bond in feature['bonds']]\n",
        "    for b in a:\n",
        "      print(len(b), target)\n",
        "    # bond_feat = [d['bonds'] for d in feature]\n",
        "\n",
        "\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4m6ZahKoKYR",
        "outputId": "1710f8d9-8edc-4286-e2d2-7a3a1c640f35"
      },
      "id": "k4m6ZahKoKYR",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17 tensor(-395.5993)\n",
            "17 tensor(-395.5993)\n",
            "17 tensor(-395.5993)\n",
            "17 tensor(-395.5993)\n",
            "17 tensor(-395.5993)\n",
            "17 tensor(-395.5993)\n",
            "17 tensor(-395.5993)\n",
            "17 tensor(-395.5993)\n",
            "17 tensor(-395.5993)\n",
            "17 tensor(-395.5993)\n",
            "17 tensor(-395.5993)\n",
            "17 tensor(-395.5993)\n",
            "17 tensor(-395.5993)\n",
            "17 tensor(-395.5993)\n",
            "17 tensor(-395.5993)\n",
            "17 tensor(-384.8853)\n",
            "17 tensor(-384.8853)\n",
            "17 tensor(-384.8853)\n",
            "17 tensor(-384.8853)\n",
            "17 tensor(-384.8853)\n",
            "17 tensor(-384.8853)\n",
            "17 tensor(-384.8853)\n",
            "17 tensor(-384.8853)\n",
            "17 tensor(-384.8853)\n",
            "17 tensor(-384.8853)\n",
            "17 tensor(-384.8853)\n",
            "17 tensor(-384.8853)\n",
            "17 tensor(-384.8853)\n",
            "17 tensor(-384.8853)\n",
            "17 tensor(-384.8853)\n",
            "17 tensor(-384.8853)\n",
            "17 tensor(-384.8853)\n",
            "17 tensor(-384.8853)\n",
            "17 tensor(-384.8853)\n",
            "17 tensor(-384.8853)\n",
            "17 tensor(-384.8853)\n",
            "17 tensor(-399.5984)\n",
            "17 tensor(-399.5984)\n",
            "17 tensor(-399.5984)\n",
            "17 tensor(-399.5984)\n",
            "17 tensor(-399.5984)\n",
            "17 tensor(-399.5984)\n",
            "17 tensor(-399.5984)\n",
            "17 tensor(-399.5984)\n",
            "17 tensor(-399.5984)\n",
            "17 tensor(-399.5984)\n",
            "17 tensor(-399.5984)\n",
            "17 tensor(-399.5984)\n",
            "17 tensor(-399.5984)\n",
            "17 tensor(-399.5984)\n",
            "17 tensor(-399.5984)\n",
            "17 tensor(-399.5984)\n",
            "17 tensor(-399.5984)\n",
            "17 tensor(-399.5984)\n",
            "17 tensor(-399.5984)\n",
            "17 tensor(-399.5984)\n",
            "17 tensor(-361.1540)\n",
            "17 tensor(-361.1540)\n",
            "17 tensor(-361.1540)\n",
            "17 tensor(-361.1540)\n",
            "17 tensor(-361.1540)\n",
            "17 tensor(-361.1540)\n",
            "17 tensor(-361.1540)\n",
            "17 tensor(-361.1540)\n",
            "17 tensor(-361.1540)\n",
            "17 tensor(-361.1540)\n",
            "17 tensor(-361.1540)\n",
            "17 tensor(-361.1540)\n",
            "17 tensor(-361.1540)\n",
            "17 tensor(-361.1540)\n",
            "17 tensor(-361.1540)\n",
            "17 tensor(-361.1540)\n",
            "17 tensor(-361.1540)\n",
            "17 tensor(-361.1540)\n",
            "17 tensor(-361.1540)\n",
            "17 tensor(-343.9373)\n",
            "17 tensor(-343.9373)\n",
            "17 tensor(-343.9373)\n",
            "17 tensor(-343.9373)\n",
            "17 tensor(-343.9373)\n",
            "17 tensor(-343.9373)\n",
            "17 tensor(-343.9373)\n",
            "17 tensor(-343.9373)\n",
            "17 tensor(-343.9373)\n",
            "17 tensor(-343.9373)\n",
            "17 tensor(-343.9373)\n",
            "17 tensor(-343.9373)\n",
            "17 tensor(-343.9373)\n",
            "17 tensor(-343.9373)\n",
            "17 tensor(-343.9373)\n",
            "17 tensor(-343.9373)\n",
            "17 tensor(-343.9373)\n",
            "17 tensor(-343.9373)\n",
            "17 tensor(-343.9373)\n",
            "17 tensor(-343.9373)\n",
            "17 tensor(-343.9373)\n",
            "17 tensor(-343.9373)\n",
            "17 tensor(-395.8009)\n",
            "17 tensor(-395.8009)\n",
            "17 tensor(-395.8009)\n",
            "17 tensor(-395.8009)\n",
            "17 tensor(-395.8009)\n",
            "17 tensor(-395.8009)\n",
            "17 tensor(-395.8009)\n",
            "17 tensor(-395.8009)\n",
            "17 tensor(-395.8009)\n",
            "17 tensor(-395.8009)\n",
            "17 tensor(-395.8009)\n",
            "17 tensor(-395.8009)\n",
            "17 tensor(-395.8009)\n",
            "17 tensor(-395.8009)\n",
            "17 tensor(-395.8009)\n",
            "17 tensor(-359.8102)\n",
            "17 tensor(-359.8102)\n",
            "17 tensor(-359.8102)\n",
            "17 tensor(-359.8102)\n",
            "17 tensor(-359.8102)\n",
            "17 tensor(-359.8102)\n",
            "17 tensor(-359.8102)\n",
            "17 tensor(-359.8102)\n",
            "17 tensor(-359.8102)\n",
            "17 tensor(-359.8102)\n",
            "17 tensor(-359.8102)\n",
            "17 tensor(-359.8102)\n",
            "17 tensor(-359.8102)\n",
            "17 tensor(-359.8102)\n",
            "17 tensor(-359.8102)\n",
            "17 tensor(-359.8102)\n",
            "17 tensor(-359.8102)\n",
            "17 tensor(-345.1334)\n",
            "17 tensor(-345.1334)\n",
            "17 tensor(-345.1334)\n",
            "17 tensor(-345.1334)\n",
            "17 tensor(-345.1334)\n",
            "17 tensor(-345.1334)\n",
            "17 tensor(-345.1334)\n",
            "17 tensor(-345.1334)\n",
            "17 tensor(-345.1334)\n",
            "17 tensor(-345.1334)\n",
            "17 tensor(-345.1334)\n",
            "17 tensor(-345.1334)\n",
            "17 tensor(-345.1334)\n",
            "17 tensor(-345.1334)\n",
            "17 tensor(-345.1334)\n",
            "17 tensor(-345.1334)\n",
            "17 tensor(-345.1334)\n",
            "17 tensor(-345.1334)\n",
            "17 tensor(-345.1334)\n",
            "17 tensor(-347.8289)\n",
            "17 tensor(-347.8289)\n",
            "17 tensor(-347.8289)\n",
            "17 tensor(-347.8289)\n",
            "17 tensor(-347.8289)\n",
            "17 tensor(-347.8289)\n",
            "17 tensor(-347.8289)\n",
            "17 tensor(-347.8289)\n",
            "17 tensor(-347.8289)\n",
            "17 tensor(-347.8289)\n",
            "17 tensor(-347.8289)\n",
            "17 tensor(-347.8289)\n",
            "17 tensor(-347.8289)\n",
            "17 tensor(-347.8289)\n",
            "17 tensor(-347.8289)\n",
            "17 tensor(-347.8289)\n",
            "17 tensor(-347.8289)\n",
            "17 tensor(-329.0763)\n",
            "17 tensor(-329.0763)\n",
            "17 tensor(-329.0763)\n",
            "17 tensor(-329.0763)\n",
            "17 tensor(-329.0763)\n",
            "17 tensor(-329.0763)\n",
            "17 tensor(-329.0763)\n",
            "17 tensor(-329.0763)\n",
            "17 tensor(-329.0763)\n",
            "17 tensor(-329.0763)\n",
            "17 tensor(-329.0763)\n",
            "17 tensor(-329.0763)\n",
            "17 tensor(-329.0763)\n",
            "17 tensor(-329.0763)\n",
            "17 tensor(-329.0763)\n",
            "17 tensor(-329.0763)\n",
            "17 tensor(-329.0763)\n",
            "17 tensor(-329.0763)\n",
            "17 tensor(-329.0763)\n",
            "17 tensor(-329.0763)\n",
            "17 tensor(-398.3061)\n",
            "17 tensor(-398.3061)\n",
            "17 tensor(-398.3061)\n",
            "17 tensor(-398.3061)\n",
            "17 tensor(-398.3061)\n",
            "17 tensor(-398.3061)\n",
            "17 tensor(-398.3061)\n",
            "17 tensor(-398.3061)\n",
            "17 tensor(-398.3061)\n",
            "17 tensor(-398.3061)\n",
            "17 tensor(-398.3061)\n",
            "17 tensor(-345.1525)\n",
            "17 tensor(-345.1525)\n",
            "17 tensor(-345.1525)\n",
            "17 tensor(-345.1525)\n",
            "17 tensor(-345.1525)\n",
            "17 tensor(-345.1525)\n",
            "17 tensor(-345.1525)\n",
            "17 tensor(-345.1525)\n",
            "17 tensor(-345.1525)\n",
            "17 tensor(-345.1525)\n",
            "17 tensor(-345.1525)\n",
            "17 tensor(-345.1525)\n",
            "17 tensor(-345.1525)\n",
            "17 tensor(-345.1525)\n",
            "17 tensor(-345.1525)\n",
            "17 tensor(-345.1525)\n",
            "17 tensor(-345.1525)\n",
            "17 tensor(-346.1828)\n",
            "17 tensor(-346.1828)\n",
            "17 tensor(-346.1828)\n",
            "17 tensor(-346.1828)\n",
            "17 tensor(-346.1828)\n",
            "17 tensor(-346.1828)\n",
            "17 tensor(-346.1828)\n",
            "17 tensor(-346.1828)\n",
            "17 tensor(-346.1828)\n",
            "17 tensor(-346.1828)\n",
            "17 tensor(-346.1828)\n",
            "17 tensor(-346.1828)\n",
            "17 tensor(-346.1828)\n",
            "17 tensor(-346.1828)\n",
            "17 tensor(-346.1828)\n",
            "17 tensor(-346.1828)\n",
            "17 tensor(-346.1828)\n",
            "17 tensor(-346.1828)\n",
            "17 tensor(-346.1828)\n",
            "17 tensor(-346.1828)\n",
            "17 tensor(-346.1828)\n",
            "17 tensor(-346.1828)\n",
            "17 tensor(-348.8875)\n",
            "17 tensor(-348.8875)\n",
            "17 tensor(-348.8875)\n",
            "17 tensor(-348.8875)\n",
            "17 tensor(-348.8875)\n",
            "17 tensor(-348.8875)\n",
            "17 tensor(-348.8875)\n",
            "17 tensor(-348.8875)\n",
            "17 tensor(-348.8875)\n",
            "17 tensor(-348.8875)\n",
            "17 tensor(-348.8875)\n",
            "17 tensor(-348.8875)\n",
            "17 tensor(-348.8875)\n",
            "17 tensor(-348.8875)\n",
            "17 tensor(-348.8875)\n",
            "17 tensor(-348.8875)\n",
            "17 tensor(-348.8875)\n",
            "17 tensor(-348.8875)\n",
            "17 tensor(-348.8875)\n",
            "17 tensor(-348.8875)\n",
            "17 tensor(-348.8875)\n",
            "17 tensor(-348.9685)\n",
            "17 tensor(-348.9685)\n",
            "17 tensor(-348.9685)\n",
            "17 tensor(-348.9685)\n",
            "17 tensor(-348.9685)\n",
            "17 tensor(-348.9685)\n",
            "17 tensor(-348.9685)\n",
            "17 tensor(-348.9685)\n",
            "17 tensor(-348.9685)\n",
            "17 tensor(-348.9685)\n",
            "17 tensor(-348.9685)\n",
            "17 tensor(-348.9685)\n",
            "17 tensor(-348.9685)\n",
            "17 tensor(-348.9685)\n",
            "17 tensor(-348.9685)\n",
            "17 tensor(-348.9685)\n",
            "17 tensor(-348.9685)\n",
            "17 tensor(-348.9685)\n",
            "17 tensor(-348.9685)\n",
            "17 tensor(-348.9685)\n",
            "17 tensor(-411.8155)\n",
            "17 tensor(-411.8155)\n",
            "17 tensor(-411.8155)\n",
            "17 tensor(-411.8155)\n",
            "17 tensor(-411.8155)\n",
            "17 tensor(-411.8155)\n",
            "17 tensor(-411.8155)\n",
            "17 tensor(-411.8155)\n",
            "17 tensor(-411.8155)\n",
            "17 tensor(-411.8155)\n",
            "17 tensor(-411.8155)\n",
            "17 tensor(-411.8155)\n",
            "17 tensor(-411.8155)\n",
            "17 tensor(-399.4953)\n",
            "17 tensor(-399.4953)\n",
            "17 tensor(-399.4953)\n",
            "17 tensor(-399.4953)\n",
            "17 tensor(-399.4953)\n",
            "17 tensor(-399.4953)\n",
            "17 tensor(-399.4953)\n",
            "17 tensor(-399.4953)\n",
            "17 tensor(-399.4953)\n",
            "17 tensor(-399.4953)\n",
            "17 tensor(-399.4953)\n",
            "17 tensor(-399.4953)\n",
            "17 tensor(-399.4953)\n",
            "17 tensor(-399.4953)\n",
            "17 tensor(-399.4953)\n",
            "17 tensor(-399.4953)\n",
            "17 tensor(-399.4953)\n",
            "17 tensor(-379.9033)\n",
            "17 tensor(-379.9033)\n",
            "17 tensor(-379.9033)\n",
            "17 tensor(-379.9033)\n",
            "17 tensor(-379.9033)\n",
            "17 tensor(-379.9033)\n",
            "17 tensor(-379.9033)\n",
            "17 tensor(-379.9033)\n",
            "17 tensor(-379.9033)\n",
            "17 tensor(-379.9033)\n",
            "17 tensor(-379.9033)\n",
            "17 tensor(-379.9033)\n",
            "17 tensor(-379.9033)\n",
            "17 tensor(-379.9033)\n",
            "17 tensor(-379.9033)\n",
            "17 tensor(-379.9033)\n",
            "17 tensor(-379.9033)\n",
            "17 tensor(-379.9033)\n",
            "17 tensor(-379.9033)\n",
            "17 tensor(-379.9033)\n",
            "17 tensor(-379.9033)\n",
            "17 tensor(-329.0988)\n",
            "17 tensor(-329.0988)\n",
            "17 tensor(-329.0988)\n",
            "17 tensor(-329.0988)\n",
            "17 tensor(-329.0988)\n",
            "17 tensor(-329.0988)\n",
            "17 tensor(-329.0988)\n",
            "17 tensor(-329.0988)\n",
            "17 tensor(-329.0988)\n",
            "17 tensor(-329.0988)\n",
            "17 tensor(-329.0988)\n",
            "17 tensor(-329.0988)\n",
            "17 tensor(-329.0988)\n",
            "17 tensor(-329.0988)\n",
            "17 tensor(-329.0988)\n",
            "17 tensor(-329.0988)\n",
            "17 tensor(-329.0988)\n",
            "17 tensor(-329.0988)\n",
            "17 tensor(-329.0988)\n",
            "17 tensor(-329.0988)\n",
            "17 tensor(-327.7053)\n",
            "17 tensor(-327.7053)\n",
            "17 tensor(-327.7053)\n",
            "17 tensor(-327.7053)\n",
            "17 tensor(-327.7053)\n",
            "17 tensor(-327.7053)\n",
            "17 tensor(-327.7053)\n",
            "17 tensor(-327.7053)\n",
            "17 tensor(-327.7053)\n",
            "17 tensor(-327.7053)\n",
            "17 tensor(-327.7053)\n",
            "17 tensor(-327.7053)\n",
            "17 tensor(-327.7053)\n",
            "17 tensor(-327.7053)\n",
            "17 tensor(-327.7053)\n",
            "17 tensor(-327.7053)\n",
            "17 tensor(-312.8397)\n",
            "17 tensor(-312.8397)\n",
            "17 tensor(-312.8397)\n",
            "17 tensor(-312.8397)\n",
            "17 tensor(-312.8397)\n",
            "17 tensor(-312.8397)\n",
            "17 tensor(-312.8397)\n",
            "17 tensor(-312.8397)\n",
            "17 tensor(-312.8397)\n",
            "17 tensor(-312.8397)\n",
            "17 tensor(-312.8397)\n",
            "17 tensor(-312.8397)\n",
            "17 tensor(-312.8397)\n",
            "17 tensor(-312.8397)\n",
            "17 tensor(-312.8397)\n",
            "17 tensor(-312.8397)\n",
            "17 tensor(-312.8397)\n",
            "17 tensor(-312.8397)\n",
            "17 tensor(-312.8397)\n",
            "17 tensor(-312.8397)\n",
            "17 tensor(-312.8397)\n",
            "17 tensor(-364.9969)\n",
            "17 tensor(-364.9969)\n",
            "17 tensor(-364.9969)\n",
            "17 tensor(-364.9969)\n",
            "17 tensor(-364.9969)\n",
            "17 tensor(-364.9969)\n",
            "17 tensor(-364.9969)\n",
            "17 tensor(-364.9969)\n",
            "17 tensor(-364.9969)\n",
            "17 tensor(-364.9969)\n",
            "17 tensor(-364.9969)\n",
            "17 tensor(-364.9969)\n",
            "17 tensor(-364.9969)\n",
            "17 tensor(-364.9969)\n",
            "17 tensor(-364.9969)\n",
            "17 tensor(-364.9969)\n",
            "17 tensor(-364.9969)\n",
            "17 tensor(-364.9969)\n",
            "17 tensor(-364.9969)\n",
            "17 tensor(-395.9281)\n",
            "17 tensor(-395.9281)\n",
            "17 tensor(-395.9281)\n",
            "17 tensor(-395.9281)\n",
            "17 tensor(-395.9281)\n",
            "17 tensor(-395.9281)\n",
            "17 tensor(-395.9281)\n",
            "17 tensor(-395.9281)\n",
            "17 tensor(-395.9281)\n",
            "17 tensor(-395.9281)\n",
            "17 tensor(-395.9281)\n",
            "17 tensor(-395.9281)\n",
            "17 tensor(-395.9281)\n",
            "17 tensor(-395.9281)\n",
            "17 tensor(-395.9281)\n",
            "17 tensor(-395.9281)\n",
            "17 tensor(-395.9281)\n",
            "17 tensor(-395.9281)\n",
            "17 tensor(-395.9281)\n",
            "17 tensor(-395.9281)\n",
            "17 tensor(-395.9281)\n",
            "17 tensor(-419.5670)\n",
            "17 tensor(-419.5670)\n",
            "17 tensor(-419.5670)\n",
            "17 tensor(-419.5670)\n",
            "17 tensor(-419.5670)\n",
            "17 tensor(-419.5670)\n",
            "17 tensor(-419.5670)\n",
            "17 tensor(-419.5670)\n",
            "17 tensor(-419.5670)\n",
            "17 tensor(-419.5670)\n",
            "17 tensor(-419.5670)\n",
            "17 tensor(-419.5670)\n",
            "17 tensor(-419.5670)\n",
            "17 tensor(-419.5670)\n",
            "17 tensor(-419.5670)\n",
            "17 tensor(-419.5670)\n",
            "17 tensor(-419.5670)\n",
            "17 tensor(-419.5670)\n",
            "17 tensor(-419.5670)\n",
            "17 tensor(-379.6224)\n",
            "17 tensor(-379.6224)\n",
            "17 tensor(-379.6224)\n",
            "17 tensor(-379.6224)\n",
            "17 tensor(-379.6224)\n",
            "17 tensor(-379.6224)\n",
            "17 tensor(-379.6224)\n",
            "17 tensor(-379.6224)\n",
            "17 tensor(-379.6224)\n",
            "17 tensor(-379.6224)\n",
            "17 tensor(-379.6224)\n",
            "17 tensor(-379.6224)\n",
            "17 tensor(-379.6224)\n",
            "17 tensor(-379.6224)\n",
            "17 tensor(-379.6224)\n",
            "17 tensor(-379.6224)\n",
            "17 tensor(-379.6224)\n",
            "17 tensor(-379.6224)\n",
            "17 tensor(-379.6224)\n",
            "17 tensor(-399.7867)\n",
            "17 tensor(-399.7867)\n",
            "17 tensor(-399.7867)\n",
            "17 tensor(-399.7867)\n",
            "17 tensor(-399.7867)\n",
            "17 tensor(-399.7867)\n",
            "17 tensor(-399.7867)\n",
            "17 tensor(-399.7867)\n",
            "17 tensor(-399.7867)\n",
            "17 tensor(-399.7867)\n",
            "17 tensor(-399.7867)\n",
            "17 tensor(-399.7867)\n",
            "17 tensor(-399.7867)\n",
            "17 tensor(-399.7867)\n",
            "17 tensor(-399.7867)\n",
            "17 tensor(-399.7867)\n",
            "17 tensor(-399.7867)\n",
            "17 tensor(-399.7867)\n",
            "17 tensor(-399.7867)\n",
            "17 tensor(-395.7451)\n",
            "17 tensor(-395.7451)\n",
            "17 tensor(-395.7451)\n",
            "17 tensor(-395.7451)\n",
            "17 tensor(-395.7451)\n",
            "17 tensor(-395.7451)\n",
            "17 tensor(-395.7451)\n",
            "17 tensor(-395.7451)\n",
            "17 tensor(-395.7451)\n",
            "17 tensor(-395.7451)\n",
            "17 tensor(-395.7451)\n",
            "17 tensor(-395.7451)\n",
            "17 tensor(-395.7451)\n",
            "17 tensor(-395.7451)\n",
            "17 tensor(-345.0791)\n",
            "17 tensor(-345.0791)\n",
            "17 tensor(-345.0791)\n",
            "17 tensor(-345.0791)\n",
            "17 tensor(-345.0791)\n",
            "17 tensor(-345.0791)\n",
            "17 tensor(-345.0791)\n",
            "17 tensor(-345.0791)\n",
            "17 tensor(-345.0791)\n",
            "17 tensor(-345.0791)\n",
            "17 tensor(-345.0791)\n",
            "17 tensor(-345.0791)\n",
            "17 tensor(-345.0791)\n",
            "17 tensor(-345.0791)\n",
            "17 tensor(-345.0791)\n",
            "17 tensor(-345.0791)\n",
            "17 tensor(-345.0791)\n",
            "17 tensor(-345.0791)\n",
            "17 tensor(-345.0791)\n",
            "17 tensor(-345.1753)\n",
            "17 tensor(-345.1753)\n",
            "17 tensor(-345.1753)\n",
            "17 tensor(-345.1753)\n",
            "17 tensor(-345.1753)\n",
            "17 tensor(-345.1753)\n",
            "17 tensor(-345.1753)\n",
            "17 tensor(-345.1753)\n",
            "17 tensor(-345.1753)\n",
            "17 tensor(-345.1753)\n",
            "17 tensor(-345.1753)\n",
            "17 tensor(-345.1753)\n",
            "17 tensor(-345.1753)\n",
            "17 tensor(-345.1753)\n",
            "17 tensor(-345.1753)\n",
            "17 tensor(-345.1753)\n",
            "17 tensor(-345.1753)\n",
            "17 tensor(-345.1753)\n",
            "17 tensor(-345.1753)\n",
            "17 tensor(-345.1753)\n",
            "17 tensor(-345.1753)\n",
            "17 tensor(-345.1753)\n",
            "17 tensor(-311.9224)\n",
            "17 tensor(-311.9224)\n",
            "17 tensor(-311.9224)\n",
            "17 tensor(-311.9224)\n",
            "17 tensor(-311.9224)\n",
            "17 tensor(-311.9224)\n",
            "17 tensor(-311.9224)\n",
            "17 tensor(-311.9224)\n",
            "17 tensor(-311.9224)\n",
            "17 tensor(-311.9224)\n",
            "17 tensor(-311.9224)\n",
            "17 tensor(-311.9224)\n",
            "17 tensor(-311.9224)\n",
            "17 tensor(-311.9224)\n",
            "17 tensor(-311.9224)\n",
            "17 tensor(-311.9224)\n",
            "17 tensor(-311.9224)\n",
            "17 tensor(-311.9224)\n",
            "17 tensor(-311.9224)\n",
            "17 tensor(-311.9224)\n",
            "17 tensor(-330.1382)\n",
            "17 tensor(-330.1382)\n",
            "17 tensor(-330.1382)\n",
            "17 tensor(-330.1382)\n",
            "17 tensor(-330.1382)\n",
            "17 tensor(-330.1382)\n",
            "17 tensor(-330.1382)\n",
            "17 tensor(-330.1382)\n",
            "17 tensor(-330.1382)\n",
            "17 tensor(-330.1382)\n",
            "17 tensor(-330.1382)\n",
            "17 tensor(-330.1382)\n",
            "17 tensor(-330.1382)\n",
            "17 tensor(-330.1382)\n",
            "17 tensor(-330.1382)\n",
            "17 tensor(-330.1382)\n",
            "17 tensor(-330.1382)\n",
            "17 tensor(-330.1382)\n",
            "17 tensor(-330.1382)\n",
            "17 tensor(-330.1382)\n",
            "17 tensor(-330.1382)\n",
            "17 tensor(-363.8161)\n",
            "17 tensor(-363.8161)\n",
            "17 tensor(-363.8161)\n",
            "17 tensor(-363.8161)\n",
            "17 tensor(-363.8161)\n",
            "17 tensor(-363.8161)\n",
            "17 tensor(-363.8161)\n",
            "17 tensor(-363.8161)\n",
            "17 tensor(-363.8161)\n",
            "17 tensor(-363.8161)\n",
            "17 tensor(-363.8161)\n",
            "17 tensor(-363.8161)\n",
            "17 tensor(-363.8161)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_Fn(batch):\n",
        "  features_batch = [sample[0] for sample in batch]\n",
        "  targets_batch = [sample[1] for sample in batch]\n",
        "  new_feature_list = []\n",
        "  new_energy_list = []\n",
        "  for feature, target in zip(features_batch, targets_batch):\n",
        "    for i in range(len(feature)):\n",
        "      new_feature_list.append(feature[i])\n",
        "      new_energy_list.append(target)\n",
        "  return new_feature_list, new_energy_list"
      ],
      "metadata": {
        "id": "nDU7-1RVcnt8"
      },
      "id": "nDU7-1RVcnt8",
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_Fn(batch):\n",
        "  features_batch = [sample[0] for sample in batch]\n",
        "  targets_batch = [sample[1] for sample in batch]\n",
        "  new_feature_list = []\n",
        "  new_energy_list = []\n",
        "  for feature, target in zip(features_batch, targets_batch):\n",
        "    for i in range(len(feature)):\n",
        "      new_feature_list.append(feature[i])\n",
        "      new_energy_list.append(target)\n",
        "  return new_feature_list, new_energy_list"
      ],
      "metadata": {
        "id": "UFhLcAQ8gzrV"
      },
      "id": "UFhLcAQ8gzrV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "ccc3fa8c",
      "metadata": {
        "id": "ccc3fa8c"
      },
      "outputs": [],
      "source": [
        "# create CustomDataset Class\n",
        "\n",
        "class BondDataset(Dataset):\n",
        "\n",
        "  def __init__(self, bond_features, targets):\n",
        "    self.bond_features = bond_features\n",
        "    self.targets = torch.tensor(targets, dtype=torch.float32)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.targets)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.bond_features[index], self.targets[index]\n",
        "\n",
        "class AnglesDataset(Dataset):\n",
        "\n",
        "  def __init__(self, angle_features, targets):\n",
        "\n",
        "    self.angle_features = angle_features\n",
        "    self.targets = torch.tensor(targets, dtype=torch.float32)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.targets)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.angle_features[index],  self.targets[index]\n",
        "\n",
        "class NonbondData(Dataset):\n",
        "\n",
        "  def __init__(self, nonbond_features, targets):\n",
        "    self.nonbond_features = nonbond_features\n",
        "    self.targets = torch.tensor(targets, dtype=torch.float32)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.targets)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.nonbond_features[index], self.targets[index]\n",
        "\n",
        "class DihedralData(Dataset):\n",
        "\n",
        "  def __init__(self, dihedral_features, targets):\n",
        "    self.dihedral_features = dihedral_features\n",
        "    self.targets = torch.tensor(targets, dtype=torch.float32)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.targets)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.dihedral_features[index], self.targets[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "b62c574d",
      "metadata": {
        "id": "b62c574d"
      },
      "outputs": [],
      "source": [
        "# create train_dataset object\n",
        "X_train_bond_feat = [d['bonds'] for d in X_train]\n",
        "X_train_angle_feat = [d['angles'] for d in X_train]\n",
        "X_train_nonbond_feat = [d['nonbonds'] for d in X_train]\n",
        "X_train_dihedral_feat = [d['dihedrals'] for d in X_train]\n",
        "\n",
        "X_test_bond_feat = [d['bonds'] for d in X_test]\n",
        "X_test_angle_feat = [d['angles'] for d in X_test]\n",
        "X_test_nonbond_feat = [d['nonbonds'] for d in X_test]\n",
        "X_test_dihedral_Feat = [d['dihedrals'] for d in X_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "7967f113",
      "metadata": {
        "id": "7967f113"
      },
      "outputs": [],
      "source": [
        "train_dataset1 = BondDataset(X_train_bond_feat, y_train)\n",
        "test_dataset1 = BondDataset(X_test_bond_feat, y_test)\n",
        "\n",
        "train_dataset2 = AnglesDataset(X_train_angle_feat, y_train)\n",
        "test_dataset2 = AnglesDataset(X_test_angle_feat, y_test)\n",
        "\n",
        "train_dataset3 = NonbondData(X_train_nonbond_feat, y_train)\n",
        "test_dataset3 = NonbondData(X_test_nonbond_feat, y_test)\n",
        "\n",
        "train_trainset4 = DihedralData(X_train_dihedral_feat, y_train)\n",
        "test_dataset4 = DihedralData(X_test_dihedral_Feat, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "68c22e3c",
      "metadata": {
        "id": "68c22e3c"
      },
      "outputs": [],
      "source": [
        "train_loader1 = DataLoader(train_dataset1, batch_size=32,collate_fn=collate_Fn, shuffle=True, pin_memory=True)\n",
        "test_loader1 = DataLoader(test_dataset1, batch_size=32, collate_fn=collate_Fn, shuffle=False, pin_memory=True)\n",
        "\n",
        "train_loader2 = DataLoader(train_dataset2, batch_size=32, collate_fn=collate_Fn, shuffle=True, pin_memory=True)\n",
        "test_loader2 = DataLoader(test_dataset2, batch_size=32, collate_fn=collate_Fn, shuffle=False, pin_memory=True)\n",
        "\n",
        "train_loader3 = DataLoader(train_dataset3, batch_size=32, collate_fn=collate_Fn, shuffle=True, pin_memory=True)\n",
        "test_loader3 = DataLoader(test_dataset3, batch_size=32, collate_fn=collate_Fn, shuffle=False, pin_memory=True)\n",
        "\n",
        "train_loader4 = DataLoader(train_trainset4, batch_size=32, collate_fn=collate_Fn, shuffle=True, pin_memory=True)\n",
        "test_loader4 = DataLoader(test_dataset4, batch_size=32, collate_fn=collate_Fn, shuffle=False, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create CustomDataset Class\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self, bond_features, angle_features, nonbond_features, dihedral_features, targets):\n",
        "    self.bond_features = bond_features\n",
        "    self.angle_features = angle_features\n",
        "    self.nonbond_features = nonbond_features\n",
        "    self.dihedral_features = dihedral_features\n",
        "    self.targets = torch.tensor(targets, dtype=torch.float32)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.bond_features)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.bond_features[index], self.angle_features[index], self.nonbond_features[index], self.dihedral_features[index], self.targets[index]\n"
      ],
      "metadata": {
        "id": "GfD_Cr_lTvxj"
      },
      "id": "GfD_Cr_lTvxj",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = BondDataset(X_train_bond_feat, y_train)\n",
        "train_loader = DataLoader(dataset, batch_size=4, collate_fn=collate_Fn)\n",
        "for b, t in train_loader:\n",
        "  print('lengths:',len(b), len(t))\n",
        "\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yfj9_rANguz",
        "outputId": "5c279b3e-ddf3-4942-fa16-998d7c957b92"
      },
      "id": "1yfj9_rANguz",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lengths: 76 76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPec4w_oN3sl",
        "outputId": "02411c3e-8cf4-402e-d1ee-bf44e1007232"
      },
      "id": "dPec4w_oN3sl",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "t6X2ex8SLHNB",
        "outputId": "eea1d018-4659-472b-fc5f-307618db8044"
      },
      "id": "t6X2ex8SLHNB",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  295.,   868.,  2618.,  5755.,  7832., 16837., 20639., 25447.,\n",
              "        14928.,  4781.]),\n",
              " array([-471.57122759, -455.4379652 , -439.3047028 , -423.17144041,\n",
              "        -407.03817801, -390.90491562, -374.77165322, -358.63839082,\n",
              "        -342.50512843, -326.37186603, -310.23860364]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "34325958",
      "metadata": {
        "id": "34325958"
      },
      "outputs": [],
      "source": [
        "BONDS_DIM, ANGLES_DIM, NONBONDS_DIM, DIHEDRALS_DIM = 17, 27, 17, 38"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "05bfc17b",
      "metadata": {
        "id": "05bfc17b"
      },
      "outputs": [],
      "source": [
        "def make_tensor(seq):\n",
        "    return torch.tensor(seq, dtype=torch.float32, requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c55ce462",
      "metadata": {
        "id": "c55ce462"
      },
      "outputs": [],
      "source": [
        "class BANDNN(nn.Module):\n",
        "\n",
        "  def __init__(self, bonds_input_dim, angles_input_dim, nonbonds_input_dim, dihedral_input_dim):\n",
        "    super().__init__()\n",
        "    self.bonds_model = nn.Sequential(\n",
        "        nn.Linear(bonds_input_dim, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 1)\n",
        "    )\n",
        "\n",
        "    self.angles_model = nn.Sequential(\n",
        "        nn.Linear(angles_input_dim, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 350),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(350, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 1)\n",
        "    )\n",
        "\n",
        "    self.nonbonds_model = nn.Sequential(\n",
        "        nn.Linear(nonbonds_input_dim, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 1)\n",
        "    )\n",
        "\n",
        "    self.dihedrals_model = nn.Sequential(\n",
        "        nn.Linear(dihedral_input_dim, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 1)\n",
        "    )\n",
        "\n",
        "  def forward(self, bonds_input,angles_input, non_bonds_input, dihedrals_input):\n",
        "\n",
        "\n",
        "    bonds_energy = make_tensor([self.bonds_model(make_tensor(bond_input)) for bond_input in bonds_input])\n",
        "    angles_energy = make_tensor([self.angles_model(make_tensor(angle_input)) for angle_input in angles_input])\n",
        "    nonbonds_energy = make_tensor([self.nonbonds_model(make_tensor(non_bond_input))for non_bond_input in non_bonds_input])\n",
        "    dihedrals_energy =  make_tensor([self.dihedrals_model(make_tensor(dihedral_input)) for dihedral_input in dihedrals_input])\n",
        "    total_energy =  torch.sum(bonds_energy) + torch.sum(angles_energy) + torch.sum(nonbonds_energy) + torch.sum(dihedrals_energy)\n",
        "\n",
        "    return total_energy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BANDNN(nn.Module):\n",
        "    def __init__(self, bonds_input_dim, angles_input_dim, nonbonds_input_dim, dihedral_input_dim):\n",
        "        super().__init__()\n",
        "        self.bonds_model = nn.Sequential(\n",
        "            nn.Linear(bonds_input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "        self.angles_model = nn.Sequential(\n",
        "            nn.Linear(angles_input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 350),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(350, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "        self.nonbonds_model = nn.Sequential(\n",
        "            nn.Linear(nonbonds_input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "        self.dihedrals_model = nn.Sequential(\n",
        "            nn.Linear(dihedral_input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, bonds_input, angles_input, non_bonds_input, dihedrals_input):\n",
        "        bonds_energy = self.bonds_model(bonds_input).sum()\n",
        "        angles_energy = self.angles_model(angles_input).sum()\n",
        "        nonbonds_energy = self.nonbonds_model(non_bonds_input).sum()\n",
        "        dihedrals_energy = self.dihedrals_model(dihedrals_input).sum()\n",
        "\n",
        "        total_energy = bonds_energy + angles_energy + nonbonds_energy + dihedrals_energy\n",
        "        return total_energy\n"
      ],
      "metadata": {
        "id": "pCoVaLBsoliC"
      },
      "id": "pCoVaLBsoliC",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWwpXhXEO47N",
        "outputId": "ce834c07-98be-4dd7-9d84-d21172a8659f"
      },
      "id": "gWwpXhXEO47N",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "aa1b7794",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa1b7794",
        "outputId": "4d784ce8-c2a6-4e0d-c632-4bf5db41d43b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "BANDNN                                   --\n",
              "├─Sequential: 1-1                        --\n",
              "│    └─Linear: 2-1                       2,304\n",
              "│    └─ReLU: 2-2                         --\n",
              "│    └─Linear: 2-3                       33,024\n",
              "│    └─ReLU: 2-4                         --\n",
              "│    └─Linear: 2-5                       32,896\n",
              "│    └─ReLU: 2-6                         --\n",
              "│    └─Linear: 2-7                       129\n",
              "├─Sequential: 1-2                        --\n",
              "│    └─Linear: 2-8                       3,584\n",
              "│    └─ReLU: 2-9                         --\n",
              "│    └─Linear: 2-10                      45,150\n",
              "│    └─ReLU: 2-11                        --\n",
              "│    └─Linear: 2-12                      44,928\n",
              "│    └─ReLU: 2-13                        --\n",
              "│    └─Linear: 2-14                      129\n",
              "├─Sequential: 1-3                        --\n",
              "│    └─Linear: 2-15                      2,304\n",
              "│    └─ReLU: 2-16                        --\n",
              "│    └─Linear: 2-17                      33,024\n",
              "│    └─ReLU: 2-18                        --\n",
              "│    └─Linear: 2-19                      32,896\n",
              "│    └─ReLU: 2-20                        --\n",
              "│    └─Linear: 2-21                      129\n",
              "├─Sequential: 1-4                        --\n",
              "│    └─Linear: 2-22                      4,992\n",
              "│    └─ReLU: 2-23                        --\n",
              "│    └─Linear: 2-24                      66,048\n",
              "│    └─ReLU: 2-25                        --\n",
              "│    └─Linear: 2-26                      65,664\n",
              "│    └─ReLU: 2-27                        --\n",
              "│    └─Linear: 2-28                      129\n",
              "=================================================================\n",
              "Total params: 367,330\n",
              "Trainable params: 367,330\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from torchinfo import summary\n",
        "model = BANDNN(BONDS_DIM, ANGLES_DIM, NONBONDS_DIM, DIHEDRALS_DIM)\n",
        "model = model.to(device)\n",
        "# model.summary()\n",
        "summary(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "10094ccd",
      "metadata": {
        "id": "10094ccd"
      },
      "outputs": [],
      "source": [
        "epochs = 20\n",
        "learning_rate = 0.1\n",
        "\n",
        "# loss func\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    print(f'Epoch {epoch + 1}')\n",
        "    total_epoch_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        for feature, target in zip(*batch):\n",
        "            bond_feat = torch.stack([torch.tensor(arr, dtype=torch.float32) for arr in feature['bonds']]).float().to(device)\n",
        "            angle_feat = torch.stack([torch.tensor(arr, dtype=torch.float32) for arr in feature['angles']]).float().to(device)\n",
        "            nonbond_feat = torch.stack([torch.tensor(arr, dtype=torch.float32) for arr in feature['nonbonds']]).float().to(device)\n",
        "            dihedral_feat = torch.stack([torch.tensor(arr, dtype=torch.float32) for arr in feature['dihedrals']]).float().to(device)\n",
        "            energy_feat = torch.tensor([target], dtype=torch.float32).to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(bond_feat, angle_feat, nonbond_feat, dihedral_feat)\n",
        "            loss = criterion(outputs, energy_feat)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_epoch_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_epoch_loss / len(train_loader)\n",
        "    print(f'Average Loss: {avg_loss:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVryVrGIo2Rn",
        "outputId": "fb42ac0d-324d-494a-b293-afa5bd9b6c76"
      },
      "id": "WVryVrGIo2Rn",
      "execution_count": 21,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Loss: 13993593.9400\n",
            "Epoch 2\n",
            "Average Loss: 46146.8688\n",
            "Epoch 3\n",
            "Average Loss: 46307.9569\n",
            "Epoch 4\n",
            "Average Loss: 46188.7296\n",
            "Epoch 5\n",
            "Average Loss: 46090.8090\n",
            "Epoch 6\n",
            "Average Loss: 46220.3198\n",
            "Epoch 7\n",
            "Average Loss: 46356.1518\n",
            "Epoch 8\n",
            "Average Loss: 46454.3448\n",
            "Epoch 9\n",
            "Average Loss: 46186.1744\n",
            "Epoch 10\n",
            "Average Loss: 46233.9721\n",
            "Epoch 11\n",
            "Average Loss: 46293.8763\n",
            "Epoch 12\n",
            "Average Loss: 46445.6029\n",
            "Epoch 13\n",
            "Average Loss: 46438.3128\n",
            "Epoch 14\n",
            "Average Loss: 46432.8343\n",
            "Epoch 15\n",
            "Average Loss: 46544.1845\n",
            "Epoch 16\n",
            "Average Loss: 46287.3948\n",
            "Epoch 17\n",
            "Average Loss: 46213.1388\n",
            "Epoch 18\n",
            "Average Loss: 45958.2199\n",
            "Epoch 19\n",
            "Average Loss: 46444.4479\n",
            "Epoch 20\n",
            "Average Loss: 46576.0270\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'BANDNN-trained-190425.pth')"
      ],
      "metadata": {
        "id": "MorG9WqaV5HQ"
      },
      "id": "MorG9WqaV5HQ",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "3d31db22",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "3d31db22",
        "outputId": "00961640-37fc-4403-f791-114340fd9a13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch, number 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-8c7c59d5484c>:8: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
            "  bond_feat = torch.tensor([bond for bond in feature['bonds']], dtype=torch.float32, requires_grad=True)\n",
            "<ipython-input-18-8c7c59d5484c>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  energy_feat = torch.tensor(target, dtype=torch.float32, requires_grad=True).to(device)\n",
            "<ipython-input-13-0c50ae6595e1>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.tensor(seq, dtype=torch.float32, requires_grad=True)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-8c7c59d5484c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0menergy_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbond_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonbond_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdihedral_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menergy_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-c32182cb0fe4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, bonds_input, angles_input, non_bonds_input, dihedrals_input)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mangles_energy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mangles_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangle_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mangle_input\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mangles_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mnonbonds_energy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonbonds_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_bond_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;32mfor\u001b[0m \u001b[0mnon_bond_input\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnon_bonds_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mdihedrals_energy\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmake_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdihedrals_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdihedral_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdihedral_input\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdihedrals_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mtotal_energy\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbonds_energy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangles_energy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnonbonds_energy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdihedrals_energy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-c32182cb0fe4>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mangles_energy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mangles_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangle_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mangle_input\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mangles_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mnonbonds_energy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonbonds_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_bond_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;32mfor\u001b[0m \u001b[0mnon_bond_input\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnon_bonds_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mdihedrals_energy\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmake_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdihedrals_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdihedral_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdihedral_input\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdihedrals_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mtotal_energy\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbonds_energy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangles_energy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnonbonds_energy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdihedrals_energy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1913\u001b[0m     \u001b[0;31m# on `torch.nn.Module` and all its subclasses is largely disabled as a result. See:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m     \u001b[0;31m# https://github.com/pytorch/pytorch/pull/115074\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1915\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Module\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_parameters\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_parameters\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# training loop\n",
        "for epoch in range(epochs):\n",
        "    print('epoch, number', epoch)\n",
        "    total_epoch_loss = 0\n",
        "    for batch in train_loader:\n",
        "\n",
        "      for feature, target in zip(*batch):\n",
        "        bond_feat = torch.tensor([bond for bond in feature['bonds']], dtype=torch.float32, requires_grad=True)\n",
        "        angle_feat = torch.tensor([angle for angle in feature['angles']], dtype=torch.float32, requires_grad=True)\n",
        "        nonbond_feat = torch.tensor([nonbond for nonbond in feature['nonbonds']], dtype=torch.float32, requires_grad=True)\n",
        "        dihedral_feat = torch.tensor([dihedral for dihedral in feature['dihedrals']], dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "        bond_feat = bond_feat.to(device)\n",
        "        angle_feat = angle_feat.to(device)\n",
        "        nonbond_feat = nonbond_feat.to(device)\n",
        "        dihedral_feat = dihedral_feat.to(device)\n",
        "        energy_feat = torch.tensor(target, dtype=torch.float32, requires_grad=True).to(device)\n",
        "\n",
        "        outputs = model(bond_feat, angle_feat, nonbond_feat, dihedral_feat).to(device)\n",
        "\n",
        "        loss = criterion(outputs, energy_feat)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # back pass\n",
        "        loss.backward()\n",
        "\n",
        "        # update params\n",
        "        optimizer.step()\n",
        "\n",
        "        total_epoch_loss = total_epoch_loss + loss.item()\n",
        "\n",
        "    avg_loss = total_epoch_loss/len(train_loader)\n",
        "    print(f'Epoch {epoch+1}, Loss: {avg_loss: .4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3dc16d6",
      "metadata": {
        "id": "f3dc16d6",
        "outputId": "d243527f-c543-4aa8-fd4b-42d1887c7828"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BANDNN(\n",
              "  (bonds_model): Sequential(\n",
              "    (0): Linear(in_features=17, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
              "  )\n",
              "  (angles_model): Sequential(\n",
              "    (0): Linear(in_features=27, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=128, out_features=350, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=350, out_features=128, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
              "  )\n",
              "  (nonbonds_model): Sequential(\n",
              "    (0): Linear(in_features=17, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
              "  )\n",
              "  (dihedrals_model): Sequential(\n",
              "    (0): Linear(in_features=38, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=128, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=512, out_features=128, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81151494",
      "metadata": {
        "id": "81151494"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}